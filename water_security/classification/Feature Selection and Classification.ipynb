{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sfs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "#from data.dataset import DATASET_AUG as aug\n",
    "from data.dataset import DATASET as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = aug[aug.columns.drop([\"latitude\", \"longitude\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "risks = list(dt.filter(like='risk').columns)\n",
    "aug = aug.append(dt[risks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "       ... \n",
       "1206    NaN\n",
       "1207    NaN\n",
       "1208    NaN\n",
       "1209    0.0\n",
       "1210    NaN\n",
       "Name: risk0, Length: 1210, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dt = aug.copy()\n",
    "# dt[\"risk0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>population</th>\n",
       "      <th>country_code</th>\n",
       "      <th>c40</th>\n",
       "      <th>risk0</th>\n",
       "      <th>risk1</th>\n",
       "      <th>risk2</th>\n",
       "      <th>risk3</th>\n",
       "      <th>...</th>\n",
       "      <th>SDG 6.4.1. Water Use Efficiency</th>\n",
       "      <th>SDG 6.4.2. Water Stress</th>\n",
       "      <th>Seasonal variability (WRI)</th>\n",
       "      <th>Total internal renewable water resources per capita</th>\n",
       "      <th>Total population with access to safe drinking-water (JMP)</th>\n",
       "      <th>Total renewable water resources per capita</th>\n",
       "      <th>Total water withdrawal per capita</th>\n",
       "      <th>Urban population with access to safe drinking-water (JMP)</th>\n",
       "      <th>country</th>\n",
       "      <th>population_1k_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aalborg</td>\n",
       "      <td>57.0337</td>\n",
       "      <td>9.9166</td>\n",
       "      <td>122219.0</td>\n",
       "      <td>DNK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368.612902</td>\n",
       "      <td>20.040562</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>129.285516</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1289.757080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>56.1572</td>\n",
       "      <td>10.2107</td>\n",
       "      <td>237551.0</td>\n",
       "      <td>DNK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368.612902</td>\n",
       "      <td>20.040562</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>129.285516</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2450.983398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Copenhagen</td>\n",
       "      <td>55.6786</td>\n",
       "      <td>12.5635</td>\n",
       "      <td>1085000.0</td>\n",
       "      <td>DNK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>368.612902</td>\n",
       "      <td>20.040562</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>129.285516</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>6691.528320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Esbjerg</td>\n",
       "      <td>55.4670</td>\n",
       "      <td>8.4500</td>\n",
       "      <td>72205.0</td>\n",
       "      <td>DNK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368.612902</td>\n",
       "      <td>20.040562</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>129.285516</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>854.210083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frederikshavn</td>\n",
       "      <td>57.4337</td>\n",
       "      <td>10.5333</td>\n",
       "      <td>24103.0</td>\n",
       "      <td>DNK</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368.612902</td>\n",
       "      <td>20.040562</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1046.705025</td>\n",
       "      <td>129.285516</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>551.431763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            city  latitude  longitude  population country_code    c40  risk0  \\\n",
       "0        Aalborg   57.0337     9.9166    122219.0          DNK  False    NaN   \n",
       "1         Aarhus   56.1572    10.2107    237551.0          DNK  False    NaN   \n",
       "2     Copenhagen   55.6786    12.5635   1085000.0          DNK  False    NaN   \n",
       "3        Esbjerg   55.4670     8.4500     72205.0          DNK  False    NaN   \n",
       "4  Frederikshavn   57.4337    10.5333     24103.0          DNK  False    NaN   \n",
       "\n",
       "   risk1  risk2  risk3  ...  SDG 6.4.1. Water Use Efficiency  \\\n",
       "0    NaN    NaN    NaN  ...                       368.612902   \n",
       "1    NaN    NaN    NaN  ...                       368.612902   \n",
       "2    2.0    NaN    2.0  ...                       368.612902   \n",
       "3    NaN    NaN    NaN  ...                       368.612902   \n",
       "4    2.0    NaN    NaN  ...                       368.612902   \n",
       "\n",
       "   SDG 6.4.2. Water Stress  Seasonal variability (WRI)  \\\n",
       "0                20.040562                         1.3   \n",
       "1                20.040562                         1.3   \n",
       "2                20.040562                         1.3   \n",
       "3                20.040562                         1.3   \n",
       "4                20.040562                         1.3   \n",
       "\n",
       "   Total internal renewable water resources per capita  \\\n",
       "0                                        1046.705025     \n",
       "1                                        1046.705025     \n",
       "2                                        1046.705025     \n",
       "3                                        1046.705025     \n",
       "4                                        1046.705025     \n",
       "\n",
       "   Total population with access to safe drinking-water (JMP)  \\\n",
       "0                                              100.0           \n",
       "1                                              100.0           \n",
       "2                                              100.0           \n",
       "3                                              100.0           \n",
       "4                                              100.0           \n",
       "\n",
       "   Total renewable water resources per capita  \\\n",
       "0                                 1046.705025   \n",
       "1                                 1046.705025   \n",
       "2                                 1046.705025   \n",
       "3                                 1046.705025   \n",
       "4                                 1046.705025   \n",
       "\n",
       "   Total water withdrawal per capita  \\\n",
       "0                         129.285516   \n",
       "1                         129.285516   \n",
       "2                         129.285516   \n",
       "3                         129.285516   \n",
       "4                         129.285516   \n",
       "\n",
       "   Urban population with access to safe drinking-water (JMP)  country  \\\n",
       "0                                              100.0          Denmark   \n",
       "1                                              100.0          Denmark   \n",
       "2                                              100.0          Denmark   \n",
       "3                                              100.0          Denmark   \n",
       "4                                              100.0          Denmark   \n",
       "\n",
       "   population_1k_density  \n",
       "0            1289.757080  \n",
       "1            2450.983398  \n",
       "2            6691.528320  \n",
       "3             854.210083  \n",
       "4             551.431763  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes different risks that need a prediction. Every risk is considered as a different target of labels, namely a response variable.\n",
    "\n",
    "The aim is to build a model able to predict each risk in the most accurate way possible. However, the learning process is different for each of them, meaning that the minimum set of variables that best explain the largest amount of variance in the dataset is unique for every risk. As a consequence, the following pipeline will be executed as much time as the number of risks in order to return as more precise predictions as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step consists in splitting the dataset into training and test sets. The first will be used during the feature selection part, which is implemented using a boosted logistic regression model. This is a supervised learning approach, thus labels are needed for the regression to be carried out. In this dataset risks are assigned to only some of the cities, therefore it's wise to select as training set all the entries containing values for the given risk. All the rest will be referred to as test set, used for the classification task, since those cities will be the ones needing a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def data_splitting(dt,risk):\n",
    "    # Select the columns containing labelled risk remove labels from the dataset to define training set\n",
    "    train = dt[dt[risk].notnull()]\n",
    "    y_train = train[risk] # define response variable\n",
    "    # Remove labels from the dataset to define training set\n",
    "    train = train[dt.columns.difference(dt.filter(like = 'risk').columns,sort=False)]\n",
    "    # Remove categorical columns since they are only descriptive\n",
    "    num_cols = train._get_numeric_data().columns\n",
    "    to_drop = list(set(train.columns) - set(num_cols))\n",
    "    to_drop.append(\"c40\") #comment if aug\n",
    "    train = train[train.columns.drop(to_drop)]\n",
    "    # Define test set\n",
    "    test = dt[~dt.index.isin(train.index)]\n",
    "    test = test[test.columns.drop(to_drop)]\n",
    "    test = test[test.columns.difference(test.filter(like = 'risk').columns,sort=False)]\n",
    "    y_test = [random.randrange(4) for x in range(len(test))]\n",
    "    return train, test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a highly non-linear and complex relationship between the predictors and the labels decision trees are preferable. The dataset has many different predictors and we don't know whether this relationship is linear or not.\n",
    "\n",
    "The most robust approach among the ensemble method is `Boosting`. It allows to aggregate many decision trees, differently from `Random Forest`, and grow them sequentially, instead of using boostrap sampling like in `Bagging`. \n",
    "\n",
    "The procedure consists in fitting small trees to the residuals in order to slowly improve the prediction error. Generally, model that learn slowly tend to perform better. A pitfall of Boosting, however, is that it relies very much on its tuning parameters. Hence, it's important to undergo `Cross Validation` in order to select the combination returning the highest accuracy, for every target. \n",
    "For this purpose we decided to use 10-fold cross validation in such a way to speed up the tuning process, which is already slow given the amount of parameters that need to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "model = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XgBoost has as default objective function `reg:squarederror`, which corresponds to a linear regression with mean-squared error as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting_reg(train, y_train, risk, best_parameters):\n",
    "    \n",
    "    '''Cross Validation'''\n",
    "    \n",
    "    kfold = KFold(n_splits=10)\n",
    "    reg_cv = GridSearchCV(model, cv = kfold,\n",
    "                          param_grid = {\"colsample_bytree\":[0.1,0.5,1.0],\"min_child_weight\":[1.0,1.2],\n",
    "                            'max_depth': [7,9], 'n_estimators': [500], \"alpha\": [10,12,15], \"subsample\": [0.5],\n",
    "                                    \"objective\": [\"reg:squarederror\"]})\n",
    "                            #\"objective\": [\"multi:softmax\", \"multi:softprob\", \"rank:map\"], \"n_classes\": 4'''    \n",
    "    reg_cv.fit(train,y_train)\n",
    "    best_parameters[risk] = reg_cv.best_params_\n",
    "    \n",
    "    '''Training'''\n",
    "    \n",
    "    gbm = xgb.XGBRegressor(**best_parameters[risk])\n",
    "    gbm.fit(train,y_train)\n",
    "    \n",
    "    '''Feature selection\n",
    "    im=pd.DataFrame({'importance':gbm.feature_importances_,'var':X.columns})\n",
    "    im=im.sort_values(by='importance',ascending=False)\n",
    "    fig,ax = plt.subplots(figsize=(8,8))\n",
    "    plot_importance(xgb,max_num_features=15,ax=ax,importance_type='gain')\n",
    "    plt.show()'''\n",
    "    \n",
    "    # accuracy_scores[risk]=[gbm.score(train,y_train),0]   \n",
    "    sorted_idx = np.argsort(gbm.feature_importances_)[::-1]\n",
    "    best_features = list()\n",
    "    for index in sorted_idx:\n",
    "        if gbm.feature_importances_[index] > 0:\n",
    "            best_features.append(train.columns[index]) \n",
    "    return gbm, best_features[:15], best_parameters#, accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boosting_clas(gbm, test, y_test, risk, accuracy_scores):\n",
    "    \n",
    "    predictions = gbm.predict(test, iteration_range = (0, gbm.best_iteration)).argmax(axis=0)\n",
    "    accuracy_scores[risk] = [gbm.score(test,y_test),0] #old\n",
    "    accuracy_scores[risk][1] = accuracy_score(y_test, predictions) #new\n",
    "    \n",
    "    return predictions, accuracy_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of a reduced dataset filled with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 298 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-ba715f3cc61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# gbm.load_model(fname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboosting_clas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfilled_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-188-44cfcebb23bf>\u001b[0m in \u001b[0;36mboosting_clas\u001b[0;34m(gbm, test, y_test, risk, accuracy_scores)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maccuracy_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maccuracy_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0m\u001b[1;32m    260\u001b[0m                             \" a valid collection.\" % x)\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array 298 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "#WIP\n",
    "\n",
    "risks = [\"risk3\"]#list(dt.filter(like='risk').columns)\n",
    "best_parameters = dict()\n",
    "accuracy_scores = dict()\n",
    "filled_dataset = dt.copy()\n",
    "\n",
    "for risk in risks:\n",
    "    train, test, y_train, y_test = data_splitting(dt,risk)\n",
    "    gbm, features, best_parameters = boosting_reg(train, y_train, risk, best_parameters)\n",
    "    fname = risk+\"_\"+\"boost_model.json\"\n",
    "    gbm.save_model(fname)\n",
    "    # gbm.load_model(fname)\n",
    "\n",
    "    predictions, accuracy_scores = boosting_clas(gbm, test, y_test, risk, accuracy_scores)\n",
    "    test_index = dt.index.isin(test.index)\n",
    "    filled_dataset.loc[test_index, risk] = predictions.round()\n",
    "    \n",
    "    get_back = [\"city\", \"country\", risk]\n",
    "    to_drop = set(dt.columns) - set(features) - set(get_back)\n",
    "    filled_red_dataset = filled_dataset[dt.columns.drop(to_drop)]\n",
    "    \n",
    "    filled_red_dataset.to_csv(risk+\"_\"+'filled_red_dataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 15,\n",
       " 'colsample_bytree': 0.1,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 1.0,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters[\"risk0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'risk0': [-0.45550314401437486, 0], 'risk1': [-0.004324828429177252, 0]}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
