{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sfs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from model_handler import ModelHandler\n",
    "from feature_selection import FeatureSelectionAndGeneration\n",
    "handler = ModelHandler()\n",
    "dataset = handler.dataset\n",
    "train_set = dataset[handler.train_mask]\n",
    "test_set = dataset[~handler.train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# y_test = [random.randrange(4) for x in range(len(test_set))] -> I don't understand if you retrieve it from somewhere else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes different risks that need a prediction. Every risk is considered as a different target of labels, namely a response variable.\n",
    "\n",
    "The aim is to build a model able to predict each risk in the most accurate way possible. However, the learning process is different for each of them, meaning that the minimum set of variables that best explain the largest amount of variance in the dataset is unique for every risk. As a consequence, the following pipeline will be executed as much time as the number of risks in order to return as more precise predictions as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step consists in splitting the dataset into training and test sets. The first will be used during the feature selection part, which is implemented using a boosted logistic regression model. This is a supervised learning approach, thus labels are needed for the regression to be carried out. In this dataset risks are assigned to only some of the cities, therefore it's wise to select as training set all the entries containing values for the given risk. All the rest will be referred to as test set, used for the classification task, since those cities will be the ones needing a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a highly non-linear and complex relationship between the predictors and the labels decision trees are preferable. The dataset has many different predictors and we don't know whether this relationship is linear or not.\n",
    "\n",
    "The most robust approach among the ensemble method is `Boosting`. It allows to aggregate many decision trees, differently from `Random Forest`, and grow them sequentially, instead of using boostrap sampling like in `Bagging`. \n",
    "\n",
    "The procedure consists in fitting small trees to the residuals in order to slowly improve the prediction error. Generally, model that learn slowly tend to perform better. A pitfall of Boosting, however, is that it relies very much on its tuning parameters. Hence, it's important to undergo `Cross Validation` in order to select the combination returning the highest accuracy, for every target. \n",
    "For this purpose we decided to use 10-fold cross validation in such a way to speed up the tuning process, which is already slow given the amount of parameters that need to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import shutil\n",
    "import os\n",
    "memory_dir = '.pipeline_cache.tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XgBoost has as default objective function `reg:squarederror`, which corresponds to a linear regression with mean-squared error as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in /Users/antonella/opt/anaconda3/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/antonella/opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/antonella/opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/antonella/opt/anaconda3/lib/python3.8/site-packages (from bayesian-optimization) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/antonella/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/antonella/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "if os.path.isdir(memory_dir):\n",
    "    shutil.rmtree(memory_dir)\n",
    "\n",
    "def init_model(**model_params):\n",
    "    return Pipeline([('generation_and_selection', FeatureSelectionAndGeneration(feats_num=200)), ('classifier', xgb.XGBClassifier(**model_params,use_label_encoder=False))],memory=memory_dir)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# def boosting_reg(train, y_train, risk, best_parameters):\n",
    "    \n",
    "#     '''Cross Validation'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "**Risk: Higher water prices**\n",
      "Annotated Samples Size: 87\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 8.261   \u001b[0m | \u001b[0m 0.5943  \u001b[0m | \u001b[0m 0.9781  \u001b[0m | \u001b[0m 1.554   \u001b[0m | \u001b[0m 320.8   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.4943  \u001b[0m | \u001b[0m 6.947   \u001b[0m | \u001b[0m 0.8533  \u001b[0m | \u001b[0m 0.2975  \u001b[0m | \u001b[0m 1.408   \u001b[0m | \u001b[0m 758.0   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4713  \u001b[0m | \u001b[0m 3.671   \u001b[0m | \u001b[0m 0.6832  \u001b[0m | \u001b[0m 0.05666 \u001b[0m | \u001b[0m 5.44    \u001b[0m | \u001b[0m 684.4   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 9.094   \u001b[0m | \u001b[0m 0.7876  \u001b[0m | \u001b[0m 0.7497  \u001b[0m | \u001b[0m 3.975   \u001b[0m | \u001b[0m 790.8   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 17.54   \u001b[0m | \u001b[0m 0.4289  \u001b[0m | \u001b[0m 0.6056  \u001b[0m | \u001b[0m 4.397   \u001b[0m | \u001b[0m 445.3   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4598  \u001b[0m | \u001b[0m 2.145   \u001b[0m | \u001b[0m 0.3887  \u001b[0m | \u001b[0m 0.1292  \u001b[0m | \u001b[0m 2.345   \u001b[0m | \u001b[0m 947.1   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.4828  \u001b[0m | \u001b[0m 5.783   \u001b[0m | \u001b[0m 0.6229  \u001b[0m | \u001b[0m 0.1129  \u001b[0m | \u001b[0m 2.553   \u001b[0m | \u001b[0m 317.0   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 0.5483  \u001b[0m | \u001b[0m 0.1391  \u001b[0m | \u001b[0m 2.627   \u001b[0m | \u001b[0m 597.1   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 9.841   \u001b[0m | \u001b[0m 0.4299  \u001b[0m | \u001b[0m 0.9625  \u001b[0m | \u001b[0m 6.449   \u001b[0m | \u001b[0m 813.7   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 10.27   \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.4563  \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 372.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 15.37   \u001b[0m | \u001b[0m 0.3389  \u001b[0m | \u001b[0m 0.9847  \u001b[0m | \u001b[0m 5.478   \u001b[0m | \u001b[0m 796.6   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5057  \u001b[0m | \u001b[0m 3.278   \u001b[0m | \u001b[0m 0.891   \u001b[0m | \u001b[0m 0.5883  \u001b[0m | \u001b[0m 1.979   \u001b[0m | \u001b[0m 533.9   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4483  \u001b[0m | \u001b[0m 0.5994  \u001b[0m | \u001b[0m 0.8692  \u001b[0m | \u001b[0m 0.5607  \u001b[0m | \u001b[0m 5.967   \u001b[0m | \u001b[0m 278.4   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.4943  \u001b[0m | \u001b[0m 7.505   \u001b[0m | \u001b[0m 0.7865  \u001b[0m | \u001b[0m 0.5012  \u001b[0m | \u001b[0m 2.671   \u001b[0m | \u001b[0m 959.2   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4943  \u001b[0m | \u001b[0m 9.891   \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.1238  \u001b[0m | \u001b[0m 5.369   \u001b[0m | \u001b[0m 542.0   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 14.01   \u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 0.2302  \u001b[0m | \u001b[0m 4.897   \u001b[0m | \u001b[0m 575.8   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 14.44   \u001b[0m | \u001b[0m 0.5594  \u001b[0m | \u001b[0m 0.6562  \u001b[0m | \u001b[0m 2.364   \u001b[0m | \u001b[0m 742.8   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 13.3    \u001b[0m | \u001b[0m 0.6877  \u001b[0m | \u001b[0m 0.331   \u001b[0m | \u001b[0m 3.809   \u001b[0m | \u001b[0m 371.3   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 0.857   \u001b[0m | \u001b[0m 0.06834 \u001b[0m | \u001b[0m 3.821   \u001b[0m | \u001b[0m 372.7   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 13.25   \u001b[0m | \u001b[0m 0.3647  \u001b[0m | \u001b[0m 0.9286  \u001b[0m | \u001b[0m 2.391   \u001b[0m | \u001b[0m 326.0   \u001b[0m |\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "**Risk: Inadequate or aging infrastructure**\n",
      "Annotated Samples Size: 148\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 0.8285  \u001b[0m | \u001b[0m 0.4349  \u001b[0m | \u001b[0m 5.646   \u001b[0m | \u001b[0m 968.3   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 19.09   \u001b[0m | \u001b[0m 0.4499  \u001b[0m | \u001b[0m 0.965   \u001b[0m | \u001b[0m 5.284   \u001b[0m | \u001b[0m 341.1   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 11.14   \u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 0.4891  \u001b[0m | \u001b[0m 1.656   \u001b[0m | \u001b[0m 623.2   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 13.19   \u001b[0m | \u001b[0m 0.5013  \u001b[0m | \u001b[0m 0.03436 \u001b[0m | \u001b[0m 6.654   \u001b[0m | \u001b[0m 917.4   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 15.9    \u001b[0m | \u001b[0m 0.3182  \u001b[0m | \u001b[0m 0.4849  \u001b[0m | \u001b[0m 6.166   \u001b[0m | \u001b[0m 664.1   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 12.95   \u001b[0m | \u001b[0m 0.3927  \u001b[0m | \u001b[0m 0.2425  \u001b[0m | \u001b[0m 2.91    \u001b[0m | \u001b[0m 650.4   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 14.79   \u001b[0m | \u001b[0m 0.8572  \u001b[0m | \u001b[0m 0.07257 \u001b[0m | \u001b[0m 5.334   \u001b[0m | \u001b[0m 964.9   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 13.64   \u001b[0m | \u001b[0m 0.4035  \u001b[0m | \u001b[0m 0.5275  \u001b[0m | \u001b[0m 1.178   \u001b[0m | \u001b[0m 334.1   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 14.07   \u001b[0m | \u001b[0m 0.3139  \u001b[0m | \u001b[0m 0.3188  \u001b[0m | \u001b[0m 1.354   \u001b[0m | \u001b[0m 848.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 18.5    \u001b[0m | \u001b[0m 0.3283  \u001b[0m | \u001b[0m 0.05982 \u001b[0m | \u001b[0m 1.045   \u001b[0m | \u001b[0m 866.3   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 18.12   \u001b[0m | \u001b[0m 0.6102  \u001b[0m | \u001b[0m 0.6288  \u001b[0m | \u001b[0m 2.709   \u001b[0m | \u001b[0m 855.5   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 9.633   \u001b[0m | \u001b[0m 0.7532  \u001b[0m | \u001b[0m 0.6767  \u001b[0m | \u001b[0m 3.298   \u001b[0m | \u001b[0m 604.9   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5464  \u001b[0m | \u001b[0m 3.894   \u001b[0m | \u001b[0m 0.5466  \u001b[0m | \u001b[0m 0.3413  \u001b[0m | \u001b[0m 3.092   \u001b[0m | \u001b[0m 323.1   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.458   \u001b[0m | \u001b[0m 0.8474  \u001b[0m | \u001b[0m 0.5875  \u001b[0m | \u001b[0m 0.04862 \u001b[0m | \u001b[0m 3.034   \u001b[0m | \u001b[0m 862.8   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05063 \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 833.7   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 13.68   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.2755  \u001b[0m | \u001b[0m 5.494   \u001b[0m | \u001b[0m 938.0   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.4784  \u001b[0m | \u001b[0m 0.484   \u001b[0m | \u001b[0m 0.7762  \u001b[0m | \u001b[0m 0.7681  \u001b[0m | \u001b[0m 3.659   \u001b[0m | \u001b[0m 952.7   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4716  \u001b[0m | \u001b[0m 2.524   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 637.0   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 19.59   \u001b[0m | \u001b[0m 0.577   \u001b[0m | \u001b[0m 0.581   \u001b[0m | \u001b[0m 4.95    \u001b[0m | \u001b[0m 614.4   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6893  \u001b[0m | \u001b[0m 19.62   \u001b[0m | \u001b[0m 0.3779  \u001b[0m | \u001b[0m 0.7186  \u001b[0m | \u001b[0m 4.314   \u001b[0m | \u001b[0m 928.0   \u001b[0m |\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "**Risk: Increased water stress or scarcity**\n",
      "Annotated Samples Size: 261\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4981  \u001b[0m | \u001b[0m 0.1584  \u001b[0m | \u001b[0m 0.574   \u001b[0m | \u001b[0m 0.2138  \u001b[0m | \u001b[0m 3.278   \u001b[0m | \u001b[0m 522.3   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7126  \u001b[0m | \u001b[95m 7.031   \u001b[0m | \u001b[95m 0.6913  \u001b[0m | \u001b[95m 0.05562 \u001b[0m | \u001b[95m 4.107   \u001b[0m | \u001b[95m 846.5   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7318  \u001b[0m | \u001b[95m 17.28   \u001b[0m | \u001b[95m 0.588   \u001b[0m | \u001b[95m 0.09815 \u001b[0m | \u001b[95m 6.487   \u001b[0m | \u001b[95m 666.1   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 13.18   \u001b[0m | \u001b[0m 0.5444  \u001b[0m | \u001b[0m 0.6976  \u001b[0m | \u001b[0m 4.157   \u001b[0m | \u001b[0m 586.3   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 19.72   \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 0.6936  \u001b[0m | \u001b[0m 1.15    \u001b[0m | \u001b[0m 881.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 8.805   \u001b[0m | \u001b[0m 0.6086  \u001b[0m | \u001b[0m 0.5288  \u001b[0m | \u001b[0m 4.027   \u001b[0m | \u001b[0m 549.8   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 11.01   \u001b[0m | \u001b[0m 0.324   \u001b[0m | \u001b[0m 0.8099  \u001b[0m | \u001b[0m 2.66    \u001b[0m | \u001b[0m 864.3   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 14.33   \u001b[0m | \u001b[0m 0.5551  \u001b[0m | \u001b[0m 0.8591  \u001b[0m | \u001b[0m 6.262   \u001b[0m | \u001b[0m 606.3   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5096  \u001b[0m | \u001b[0m 0.3791  \u001b[0m | \u001b[0m 0.3267  \u001b[0m | \u001b[0m 0.02031 \u001b[0m | \u001b[0m 3.775   \u001b[0m | \u001b[0m 737.2   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 0.5117  \u001b[0m | \u001b[0m 0.6066  \u001b[0m | \u001b[0m 1.824   \u001b[0m | \u001b[0m 731.2   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 15.25   \u001b[0m | \u001b[0m 0.3052  \u001b[0m | \u001b[0m 0.9334  \u001b[0m | \u001b[0m 2.966   \u001b[0m | \u001b[0m 920.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 11.06   \u001b[0m | \u001b[0m 0.4747  \u001b[0m | \u001b[0m 0.7218  \u001b[0m | \u001b[0m 2.923   \u001b[0m | \u001b[0m 641.9   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 9.79    \u001b[0m | \u001b[0m 0.7216  \u001b[0m | \u001b[0m 0.3374  \u001b[0m | \u001b[0m 2.821   \u001b[0m | \u001b[0m 393.8   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 12.23   \u001b[0m | \u001b[0m 0.8831  \u001b[0m | \u001b[0m 0.7808  \u001b[0m | \u001b[0m 3.342   \u001b[0m | \u001b[0m 641.8   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 718.8   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 13.44   \u001b[0m | \u001b[0m 0.835   \u001b[0m | \u001b[0m 0.5752  \u001b[0m | \u001b[0m 5.261   \u001b[0m | \u001b[0m 567.0   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 11.65   \u001b[0m | \u001b[0m 0.4412  \u001b[0m | \u001b[0m 0.3482  \u001b[0m | \u001b[0m 4.168   \u001b[0m | \u001b[0m 900.4   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4981  \u001b[0m | \u001b[0m 0.2669  \u001b[0m | \u001b[0m 0.843   \u001b[0m | \u001b[0m 0.04698 \u001b[0m | \u001b[0m 5.645   \u001b[0m | \u001b[0m 882.2   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5019  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.5942  \u001b[0m | \u001b[0m 0.7009  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 562.1   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7318  \u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 0.3606  \u001b[0m | \u001b[0m 0.5939  \u001b[0m | \u001b[0m 4.897   \u001b[0m | \u001b[0m 575.7   \u001b[0m |\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "**Risk: Declining water quality**\n",
      "Annotated Samples Size: 183\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 8.192   \u001b[0m | \u001b[0m 0.7562  \u001b[0m | \u001b[0m 0.9169  \u001b[0m | \u001b[0m 2.425   \u001b[0m | \u001b[0m 485.1   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.3661  \u001b[0m | \u001b[0m 6.06    \u001b[0m | \u001b[0m 0.8346  \u001b[0m | \u001b[0m 0.04029 \u001b[0m | \u001b[0m 3.915   \u001b[0m | \u001b[0m 729.9   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 17.39   \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 0.9603  \u001b[0m | \u001b[0m 2.506   \u001b[0m | \u001b[0m 270.1   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5301  \u001b[0m | \u001b[0m 9.767   \u001b[0m | \u001b[0m 0.494   \u001b[0m | \u001b[0m 0.1898  \u001b[0m | \u001b[0m 3.05    \u001b[0m | \u001b[0m 881.7   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5355  \u001b[0m | \u001b[0m 8.736   \u001b[0m | \u001b[0m 0.357   \u001b[0m | \u001b[0m 0.2256  \u001b[0m | \u001b[0m 5.487   \u001b[0m | \u001b[0m 550.7   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5301  \u001b[0m | \u001b[0m 7.525   \u001b[0m | \u001b[0m 0.6303  \u001b[0m | \u001b[0m 0.8695  \u001b[0m | \u001b[0m 1.582   \u001b[0m | \u001b[0m 824.8   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3388  \u001b[0m | \u001b[0m 0.5487  \u001b[0m | \u001b[0m 0.5177  \u001b[0m | \u001b[0m 0.1532  \u001b[0m | \u001b[0m 3.094   \u001b[0m | \u001b[0m 365.9   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 10.2    \u001b[0m | \u001b[0m 0.8981  \u001b[0m | \u001b[0m 0.4707  \u001b[0m | \u001b[0m 6.747   \u001b[0m | \u001b[0m 351.1   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5246  \u001b[0m | \u001b[0m 7.869   \u001b[0m | \u001b[0m 0.8272  \u001b[0m | \u001b[0m 0.2558  \u001b[0m | \u001b[0m 1.553   \u001b[0m | \u001b[0m 339.2   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 15.13   \u001b[0m | \u001b[0m 0.7416  \u001b[0m | \u001b[0m 0.3458  \u001b[0m | \u001b[0m 5.975   \u001b[0m | \u001b[0m 702.0   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5301  \u001b[0m | \u001b[0m 9.583   \u001b[0m | \u001b[0m 0.5455  \u001b[0m | \u001b[0m 0.1879  \u001b[0m | \u001b[0m 1.845   \u001b[0m | \u001b[0m 485.3   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.3005  \u001b[0m | \u001b[0m 0.1704  \u001b[0m | \u001b[0m 0.6394  \u001b[0m | \u001b[0m 0.8343  \u001b[0m | \u001b[0m 6.605   \u001b[0m | \u001b[0m 474.0   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 16.93   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.4317  \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 343.9   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.377   \u001b[0m | \u001b[0m 3.667   \u001b[0m | \u001b[0m 0.8553  \u001b[0m | \u001b[0m 0.9567  \u001b[0m | \u001b[0m 3.301   \u001b[0m | \u001b[0m 495.1   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 17.29   \u001b[0m | \u001b[0m 0.488   \u001b[0m | \u001b[0m 0.4058  \u001b[0m | \u001b[0m 1.167   \u001b[0m | \u001b[0m 349.7   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 19.73   \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 336.6   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 14.21   \u001b[0m | \u001b[0m 0.4641  \u001b[0m | \u001b[0m 0.8813  \u001b[0m | \u001b[0m 6.562   \u001b[0m | \u001b[0m 330.5   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 19.57   \u001b[0m | \u001b[0m 0.3436  \u001b[0m | \u001b[0m 0.1026  \u001b[0m | \u001b[0m 5.81    \u001b[0m | \u001b[0m 691.8   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.4536  \u001b[0m | \u001b[0m 7.667   \u001b[0m | \u001b[0m 0.622   \u001b[0m | \u001b[0m 0.06196 \u001b[0m | \u001b[0m 6.203   \u001b[0m | \u001b[0m 692.4   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.541   \u001b[0m | \u001b[0m 19.14   \u001b[0m | \u001b[0m 0.4325  \u001b[0m | \u001b[0m 0.7206  \u001b[0m | \u001b[0m 1.33    \u001b[0m | \u001b[0m 321.5   \u001b[0m |\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "**Risk: Increased water demand**\n",
      "Annotated Samples Size: 98\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 15.39   \u001b[0m | \u001b[0m 0.791   \u001b[0m | \u001b[0m 0.3005  \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 481.1   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.3267  \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 0.841   \u001b[0m | \u001b[0m 0.7304  \u001b[0m | \u001b[0m 1.272   \u001b[0m | \u001b[0m 906.6   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 14.63   \u001b[0m | \u001b[0m 0.3182  \u001b[0m | \u001b[0m 0.1657  \u001b[0m | \u001b[0m 3.235   \u001b[0m | \u001b[0m 455.5   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 15.46   \u001b[0m | \u001b[0m 0.6546  \u001b[0m | \u001b[0m 0.9371  \u001b[0m | \u001b[0m 5.688   \u001b[0m | \u001b[0m 508.5   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 0.483   \u001b[0m | \u001b[0m 0.2512  \u001b[0m | \u001b[0m 5.499   \u001b[0m | \u001b[0m 875.6   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 15.52   \u001b[0m | \u001b[0m 0.3468  \u001b[0m | \u001b[0m 0.04279 \u001b[0m | \u001b[0m 5.375   \u001b[0m | \u001b[0m 459.3   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3583  \u001b[0m | \u001b[0m 9.382   \u001b[0m | \u001b[0m 0.5935  \u001b[0m | \u001b[0m 0.3245  \u001b[0m | \u001b[0m 6.86    \u001b[0m | \u001b[0m 222.8   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 0.5857  \u001b[0m | \u001b[0m 0.09968 \u001b[0m | \u001b[0m 2.104   \u001b[0m | \u001b[0m 925.8   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.4492  \u001b[0m | \u001b[95m 7.922   \u001b[0m | \u001b[95m 0.808   \u001b[0m | \u001b[95m 0.7971  \u001b[0m | \u001b[95m 4.617   \u001b[0m | \u001b[95m 950.4   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.3987  \u001b[0m | \u001b[0m 9.658   \u001b[0m | \u001b[0m 0.892   \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 6.836   \u001b[0m | \u001b[0m 413.3   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 15.8    \u001b[0m | \u001b[0m 0.5754  \u001b[0m | \u001b[0m 0.2434  \u001b[0m | \u001b[0m 4.589   \u001b[0m | \u001b[0m 971.7   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.2866  \u001b[0m | \u001b[0m 0.01447 \u001b[0m | \u001b[0m 0.3677  \u001b[0m | \u001b[0m 0.3466  \u001b[0m | \u001b[0m 6.943   \u001b[0m | \u001b[0m 961.5   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.4182  \u001b[0m | \u001b[0m 10.6    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.9464  \u001b[0m | \u001b[0m 3.887   \u001b[0m | \u001b[0m 946.9   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3583  \u001b[0m | \u001b[0m 3.959   \u001b[0m | \u001b[0m 0.8081  \u001b[0m | \u001b[0m 0.6599  \u001b[0m | \u001b[0m 4.839   \u001b[0m | \u001b[0m 947.0   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3987  \u001b[0m | \u001b[0m 8.9     \u001b[0m | \u001b[0m 0.7176  \u001b[0m | \u001b[0m 0.1063  \u001b[0m | \u001b[0m 2.236   \u001b[0m | \u001b[0m 950.5   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.3677  \u001b[0m | \u001b[0m 7.549   \u001b[0m | \u001b[0m 0.5053  \u001b[0m | \u001b[0m 0.6378  \u001b[0m | \u001b[0m 6.566   \u001b[0m | \u001b[0m 951.5   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 12.14   \u001b[0m | \u001b[0m 0.308   \u001b[0m | \u001b[0m 0.1483  \u001b[0m | \u001b[0m 4.9     \u001b[0m | \u001b[0m 457.2   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4283  \u001b[0m | \u001b[0m 9.926   \u001b[0m | \u001b[0m 0.6331  \u001b[0m | \u001b[0m 0.9871  \u001b[0m | \u001b[0m 4.184   \u001b[0m | \u001b[0m 531.3   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 15.28   \u001b[0m | \u001b[0m 0.7099  \u001b[0m | \u001b[0m 0.3631  \u001b[0m | \u001b[0m 1.887   \u001b[0m | \u001b[0m 308.7   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.4081  \u001b[0m | \u001b[0m 9.078   \u001b[0m | \u001b[0m 0.811   \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 3.933   \u001b[0m | \u001b[0m 443.5   \u001b[0m |\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "**Risk: Regulatory**\n",
      "Annotated Samples Size: 65\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 13.36   \u001b[0m | \u001b[0m 0.6247  \u001b[0m | \u001b[0m 0.6516  \u001b[0m | \u001b[0m 1.939   \u001b[0m | \u001b[0m 415.6   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 9.83    \u001b[0m | \u001b[0m 0.3176  \u001b[0m | \u001b[0m 0.4833  \u001b[0m | \u001b[0m 3.089   \u001b[0m | \u001b[0m 450.1   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.4949  \u001b[0m | \u001b[0m 0.06369 \u001b[0m | \u001b[0m 0.7287  \u001b[0m | \u001b[0m 0.8935  \u001b[0m | \u001b[0m 5.507   \u001b[0m | \u001b[0m 816.5   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6926  \u001b[0m | \u001b[0m 2.66    \u001b[0m | \u001b[0m 0.877   \u001b[0m | \u001b[0m 0.9934  \u001b[0m | \u001b[0m 5.448   \u001b[0m | \u001b[0m 847.5   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6926  \u001b[0m | \u001b[0m 4.474   \u001b[0m | \u001b[0m 0.303   \u001b[0m | \u001b[0m 0.3728  \u001b[0m | \u001b[0m 6.371   \u001b[0m | \u001b[0m 436.0   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 8.586   \u001b[0m | \u001b[0m 0.4623  \u001b[0m | \u001b[0m 0.7262  \u001b[0m | \u001b[0m 1.18    \u001b[0m | \u001b[0m 916.3   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5253  \u001b[0m | \u001b[0m 2.098   \u001b[0m | \u001b[0m 0.8703  \u001b[0m | \u001b[0m 0.03036 \u001b[0m | \u001b[0m 5.388   \u001b[0m | \u001b[0m 639.8   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 4.846   \u001b[0m | \u001b[0m 0.3938  \u001b[0m | \u001b[0m 0.7002  \u001b[0m | \u001b[0m 4.126   \u001b[0m | \u001b[0m 897.2   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6169  \u001b[0m | \u001b[0m 1.823   \u001b[0m | \u001b[0m 0.6433  \u001b[0m | \u001b[0m 0.5901  \u001b[0m | \u001b[0m 1.939   \u001b[0m | \u001b[0m 951.9   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6926  \u001b[0m | \u001b[0m 3.542   \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 0.7036  \u001b[0m | \u001b[0m 2.044   \u001b[0m | \u001b[0m 656.8   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 8.732   \u001b[0m | \u001b[0m 0.7786  \u001b[0m | \u001b[0m 0.4666  \u001b[0m | \u001b[0m 2.976   \u001b[0m | \u001b[0m 449.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 5.072   \u001b[0m | \u001b[0m 0.7111  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 676.8   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 13.92   \u001b[0m | \u001b[0m 0.6051  \u001b[0m | \u001b[0m 0.8487  \u001b[0m | \u001b[0m 1.752   \u001b[0m | \u001b[0m 870.8   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.4026  \u001b[0m | \u001b[0m 0.3467  \u001b[0m | \u001b[0m 0.7336  \u001b[0m | \u001b[0m 0.05579 \u001b[0m | \u001b[0m 1.378   \u001b[0m | \u001b[0m 390.6   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.4791  \u001b[0m | \u001b[0m 0.3694  \u001b[0m | \u001b[0m 0.4064  \u001b[0m | \u001b[0m 0.6173  \u001b[0m | \u001b[0m 4.851   \u001b[0m | \u001b[0m 479.2   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 19.7    \u001b[0m | \u001b[0m 0.8766  \u001b[0m | \u001b[0m 0.1203  \u001b[0m | \u001b[0m 1.672   \u001b[0m | \u001b[0m 431.7   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 705.1   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.4473  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 722.7   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 20.0    \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 683.8   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 19.68   \u001b[0m | \u001b[0m 0.5886  \u001b[0m | \u001b[0m 0.6776  \u001b[0m | \u001b[0m 1.875   \u001b[0m | \u001b[0m 200.2   \u001b[0m |\n",
      "=====================================================================================\n",
      "\n",
      "\n",
      "**Risk: Energy supply issues**\n",
      "Annotated Samples Size: 59\n",
      "\n",
      "|   iter    |  target   |   alpha   | colsam... |   gamma   | max_depth | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (9.224291665943925, 0.405069903776063, 0.38451774224936985, 5.632823250027073, 927.7087637209715)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 9.224   \u001b[0m | \u001b[0m 0.4051  \u001b[0m | \u001b[0m 0.3845  \u001b[0m | \u001b[0m 5.633   \u001b[0m | \u001b[0m 927.7   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (17.885140702387325, 0.6299477709799476, 0.46234766111048287, 2.2983450693476817, 977.4586737343027)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 2       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 17.89   \u001b[0m | \u001b[0m 0.6299  \u001b[0m | \u001b[0m 0.4623  \u001b[0m | \u001b[0m 2.298   \u001b[0m | \u001b[0m 977.5   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (16.42403197508265, 0.8312044559606662, 0.6892187336569529, 1.6240213815400224, 589.5250062434823)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 3       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 16.42   \u001b[0m | \u001b[0m 0.8312  \u001b[0m | \u001b[0m 0.6892  \u001b[0m | \u001b[0m 1.624   \u001b[0m | \u001b[0m 589.5   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (9.845707460002098, 0.3572957464812805, 0.7237174858251034, 1.764959627381097, 444.24890791386395)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 4       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 9.846   \u001b[0m | \u001b[0m 0.3573  \u001b[0m | \u001b[0m 0.7237  \u001b[0m | \u001b[0m 1.765   \u001b[0m | \u001b[0m 444.2   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (11.19192634866512, 0.7806634823754345, 0.1774749509121949, 1.3259293360069417, 921.4651034409363)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 5       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 11.19   \u001b[0m | \u001b[0m 0.7807  \u001b[0m | \u001b[0m 0.1775  \u001b[0m | \u001b[0m 1.326   \u001b[0m | \u001b[0m 921.5   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (5.43293847686259, 0.802894410527998, 0.8776710165710168, 5.432261527868649, 347.731657479545)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 6       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 5.433   \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 5.432   \u001b[0m | \u001b[0m 347.7   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (14.53743273094572, 0.701686896216219, 0.10935991946107115, 4.052015990438923, 618.0029600001818)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 7       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 14.54   \u001b[0m | \u001b[0m 0.7017  \u001b[0m | \u001b[0m 0.1094  \u001b[0m | \u001b[0m 4.052   \u001b[0m | \u001b[0m 618.0   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (9.065329476921924, 0.8544750746233969, 0.36315833836611344, 4.392416366632438, 883.3501831683908)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 8       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 9.065   \u001b[0m | \u001b[0m 0.8545  \u001b[0m | \u001b[0m 0.3632  \u001b[0m | \u001b[0m 4.392   \u001b[0m | \u001b[0m 883.4   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (12.152941308638823, 0.6331169762754207, 0.8796874153693808, 3.6370908607322554, 939.587050160504)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 9       \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 12.15   \u001b[0m | \u001b[0m 0.6331  \u001b[0m | \u001b[0m 0.8797  \u001b[0m | \u001b[0m 3.637   \u001b[0m | \u001b[0m 939.6   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/target_space.py\", line 191, in probe\n",
      "    target = self._cache[_hashable(x)]\n",
      "KeyError: (11.31601818770167, 0.8752055834147827, 0.47340905064803973, 3.9628918660171752, 579.3553674878542)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\", line 436, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/antonella/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1123, in fit\n",
      "    raise ValueError(label_encoding_check_error)\n",
      "ValueError: The label must consist of integer labels of form 0, 1, 2, ..., [num_class - 1].\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 10      \u001b[0m | \u001b[0m nan     \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 0.8752  \u001b[0m | \u001b[0m 0.4734  \u001b[0m | \u001b[0m 3.963   \u001b[0m | \u001b[0m 579.4   \u001b[0m |\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Queue is empty, no more objects to retrieve.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-81f6831681a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Use the expected improvement acquisition function to handle negative numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Optimally needs quite a few more initiation points and number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mxgb_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_bo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Finding argmax of the acquisition function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_vector_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             X, y = self._validate_data(X, y, multi_output=True, y_numeric=True,\n\u001b[0m\u001b[1;32m    194\u001b[0m                                        ensure_2d=True, dtype=\"numeric\")\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    878\u001b[0m                     estimator=estimator)\n\u001b[1;32m    879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n\u001b[0m\u001b[1;32m    881\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[1;32m    882\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from data.labeled.preprocessed import RISKS_MAPPING\n",
    "optimal_params = {}\n",
    "CONSTANTS = {'subsample': 0.8}\n",
    "for (risk, total_set, [train_set, valid_set]) in handler.get_total_train_val_set_per_risk():\n",
    "    print(f\"\\n\\n**Risk: {RISKS_MAPPING[risk]}**\")\n",
    "    print(f\"Annotated Samples Size: {total_set.shape[0]}\\n\")\n",
    "    def xgb_evaluate(max_depth, \n",
    "                     gamma, \n",
    "                     alpha,\n",
    "                     colsample_bytree, n_estimators):\n",
    "        params = {'max_depth': int(max_depth),\n",
    "                  'subsample': 0.8,\n",
    "                  'alpha': alpha,\n",
    "                  'gamma': gamma,\n",
    "                  'colsample_bytree': colsample_bytree,\n",
    "                   'n_estimators': int(n_estimators),\n",
    "                  \"eval_metric\": 'merror'}\n",
    "        params.update(CONSTANTS)\n",
    "\n",
    "        model = init_model(**params)\n",
    "        train_tuple = (total_set[handler.feat_names], total_set[risk])\n",
    "        reg_cv = model.fit(*train_tuple)\n",
    "        cv_result = np.mean(cross_val_score(model, *train_tuple, cv=3))\n",
    "        return cv_result\n",
    "    xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (1, 7), \n",
    "                                                 'alpha': (0,20),\n",
    "                                                 'gamma': (0, 1),\n",
    "                                                 'colsample_bytree': (0.3, 0.9),\n",
    "                                                 \"n_estimators\":[200,1000],\n",
    "                                                }\n",
    "                                  \n",
    "                                 )\n",
    "    \n",
    "    # Use the expected improvement acquisition function to handle negative numbers\n",
    "    # Optimally needs quite a few more initiation points and number of iterations\n",
    "    xgb_bo.maximize(init_points=10, n_iter=10)\n",
    "    params = xgb_bo.max['params']\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    params.update(CONSTANTS)\n",
    "    optimal_params[risk] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data.model import MODEL_BEST_PARAMS_PATH\n",
    "#pd.DataFrame(optimal_params).to_csv(MODEL_BEST_PARAMS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 148, got 27",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8d8e095a644f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#train, test, y_train, y_test = data_splitting(dt,risk)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrisk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-8d8e095a644f>\u001b[0m in \u001b[0;36mclassification\u001b[0;34m(train_tuple, valid_set, y_test, risk, best_parameters)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0miteration_range\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     ):\n\u001b[0;32m-> 1209\u001b[0;31m         class_probs = super().predict(\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_use_inplace_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 predts = self.get_booster().inplace_predict(\n\u001b[0m\u001b[1;32m    821\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1841\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1842\u001b[0m                     \u001b[0;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m                     \u001b[0;34mf\"got {data.shape[0]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 148, got 27"
     ]
    }
   ],
   "source": [
    "optimal_params = {'risk0': {'alpha': 8.261465084688773,\n",
    "  'colsample_bytree': 0.5942798565322505,\n",
    "  'gamma': 0.9780710626692427,\n",
    "  'max_depth': 1,\n",
    "  'n_estimators': 320,\n",
    "  'subsample': 0.8},\n",
    " 'risk1': {'alpha': 13.90401059454134,\n",
    "  'colsample_bytree': 0.8285387334623371,\n",
    "  'gamma': 0.4349182425943219,\n",
    "  'max_depth': 5,\n",
    "  'n_estimators': 968,\n",
    "  'subsample': 0.8},\n",
    " 'risk2': {'alpha': 17.27853343713799,\n",
    "  'colsample_bytree': 0.588032054558853,\n",
    "  'gamma': 0.0981480232590467,\n",
    "  'max_depth': 6,\n",
    "  'n_estimators': 666,\n",
    "  'subsample': 0.8},\n",
    " 'risk3': {'alpha': 8.192315865044893,\n",
    "  'colsample_bytree': 0.7562427208831419,\n",
    "  'gamma': 0.9169370907046851,\n",
    "  'max_depth': 2,\n",
    "  'n_estimators': 485,\n",
    "  'subsample': 0.8},\n",
    " 'risk4': {'alpha': 7.922430928147,\n",
    "  'colsample_bytree': 0.807955446502681,\n",
    "  'gamma': 0.7970662889259271,\n",
    "  'max_depth': 4,\n",
    "  'n_estimators': 950,\n",
    "  'subsample': 0.8},\n",
    " 'risk5': {'alpha': 13.362754510732369,\n",
    "  'colsample_bytree': 0.6246517434414811,\n",
    "  'gamma': 0.6516365370180226,\n",
    "  'max_depth': 1,\n",
    "  'n_estimators': 415,\n",
    "  'subsample': 0.8}}\n",
    "\n",
    "def classification(train_tuple, valid_set, y_test, risk, best_parameters):\n",
    "    \n",
    "    model = xgb.XGBClassifier(use_label_encoder=False,**best_parameters[risk])\n",
    "    model.fit(*train_tuple)\n",
    "    \n",
    "    y_pred = model.predict(valid_set)\n",
    "    predictions = [value for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(risk, accuracy*100.0)\n",
    "    return predictions\n",
    "\n",
    "predictions = dict()\n",
    "#risks = optimal_params.keys()\n",
    "\n",
    "'Iterate on the risks and get the partitioned data before running the classification() function'\n",
    "for (risk, total_set, [train_set, valid_set]) in handler.get_total_train_val_set_per_risk():\n",
    "    train_tuple = (total_set[handler.feat_names], total_set[risk])\n",
    "    #train, test, y_train, y_test = data_splitting(dt,risk)\n",
    "    predictions[risk] = classification(train_tuple, valid_set, y_test, risk, optimal_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
