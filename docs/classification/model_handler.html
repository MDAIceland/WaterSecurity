<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>water_security.classification.model_handler API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>water_security.classification.model_handler</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import importlib
import os
import pickle
from typing import Generator

import numpy as np
import pandas as pd
import shap
from data.model import MODEL_PATH
from data.model.metrics import (
    TRAINING_METRICS_PATH,
    VALIDATION_METRICS_PATH,
    FEATURES_IMPORTANCES_PATH,
)
from data.model.predictions import FILLED_DATASET_PATH, PREDICTION_MASK_PATH
from sklearn.base import BaseEstimator
from sklearn.exceptions import NotFittedError
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    explained_variance_score,
    mean_absolute_error,
    mean_squared_error,
)
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from utils.geo import (
    get_average_1k_population_density,
    get_elevation,
    get_place,
    is_close,
)

from classification import RANDOM_SEED
from classification.classifier import Classifier
from classification.feature_selection import FeatureSelectionAndGeneration


def regression_report(y_true, y_pred):
    &#34;&#34;&#34;
    Returns a regression report, including Mean Absolute and Squared Errors and Explained Variance
    &#34;&#34;&#34;
    return {
        &#34;MAE&#34;: mean_absolute_error(y_true, y_pred),
        &#34;MSE&#34;: mean_squared_error(y_true, y_pred),
        &#34;Explained Variance&#34;: explained_variance_score(y_true, y_pred),
    }


class TrainingRequired(NotFittedError):
    def __init__(self, obj):
        super().__init__(f&#34;{obj} could not be loaded. Training model is required&#34;)


class InvalidCoordinates(BaseException):
    pass


class ModelHandler:
    &#34;&#34;&#34;
    Trains and Tests the model, while also computing metrics.
    During training the model is first fitted, then produces predictions for any unlabled points inside the dataset
    During testing, it receives latitude, longitude, computes the required features for the city, merges with the country features,
    uses the model to predict the output and also output the shap values associated with it.
    &#34;&#34;&#34;

    def __init__(self):
        self._model = None
        self._explainers = None
        self._dataset = None
        self._valid_metrics = None
        self._train_metrics = None
        self._filled_dataset = None
        self.train_mask = None
        self.feat_names = None
        self.lab_names = None
        # The id columns to remain in the filled dataset
        self.id_columns = [
            &#34;city&#34;,
            &#34;country&#34;,
            &#34;country_code&#34;,
            &#34;c40&#34;,
            &#34;latitude&#34;,
            &#34;longitude&#34;,
            &#34;population_1k_density&#34;,
            &#34;elevation&#34;,
        ]
        # The id columns to consider also as features
        self.feat_id_columns = [
            &#34;latitude&#34;,
            &#34;longitude&#34;,
            &#34;population_1k_density&#34;,
            &#34;elevation&#34;,
        ]

    @property
    def model(self) -&gt; Pipeline:
        &#34;&#34;&#34;
        If model is not defined, try to loaded from disk
        &#34;&#34;&#34;
        if self._model is None:
            try:
                from data.model import MODEL, MODEL_PATH

                print(f&#34;Loaded model from {MODEL_PATH}.&#34;)
                self._model = MODEL
            except ImportError:
                raise TrainingRequired(&#34;Model&#34;)
        return self._model

    @model.setter
    def model(self, model: Pipeline):
        self._model = model

    def save_model(self) -&gt; None:
        &#34;&#34;&#34;
        Saves model to memory
        &#34;&#34;&#34;
        with open(os.path.join(MODEL_PATH), &#34;wb&#34;) as out:
            pickle.dump(self.model, out)
        import data.model

        importlib.reload(data.model)

    @property
    def dataset(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        The dataset for the training step.
        When it is loaded the first time, several variables are defined:
            - lab_names: the labels names/columns of the dataset
            - unique_labs: the unique labels values
            - feat_names: the features names/columns of the dataset
            - train_mask: the mask that refers to the cities that are labeled at least for one risk
        &#34;&#34;&#34;
        if self._dataset is None:
            from data.dataset import DATASET as dataset
            from data.labeled.preprocessed import LABELED_CITIES, RISKS_MAPPING

            self.lab_names = sorted(RISKS_MAPPING.keys())
            self.unique_labs = np.unique(dataset[self.lab_names].T.stack().values)
            self.feat_names = [
                x
                for x in dataset.columns
                if x not in self.lab_names
                and (x in self.feat_id_columns or x not in self.id_columns)
            ]
            self.train_mask = dataset[self.lab_names].apply(
                lambda x: not all(pd.isnull(x)), axis=1
            )
            self._dataset = dataset
        return self._dataset

    @property
    def filled_dataset(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        The dataset that has filled labels, which were produced from the predictions
        &#34;&#34;&#34;
        if self._filled_dataset is None:
            try:
                self._filled_dataset = pd.read_csv(FILLED_DATASET_PATH)
            except IOError:
                raise TrainingRequired(&#34;Filled Dataset&#34;)
        return self._filled_dataset

    @filled_dataset.setter
    def filled_dataset(self, dataset: pd.DataFrame):
        self._filled_dataset = dataset

    def compute_metrics(self, y_true, y_pred):
        &#34;&#34;&#34;
        Compute metrics for regression labels of size nx1
        &#34;&#34;&#34;
        metrics = {}

        # Interpolate predictions to labels, eg convert 0.2 to 0, 0.7 to 1 etc.
        y_pred_interp = self.unique_labs[
            np.abs(np.reshape(self.unique_labs, (-1, 1)) - y_pred).argmin(axis=0)
        ]
        metrics[&#34;confusion_matrix&#34;] = confusion_matrix(y_true, y_pred_interp)
        metrics[&#34;classification_report&#34;] = classification_report(
            y_true, y_pred_interp, output_dict=True
        )
        metrics[&#34;regression_report&#34;] = regression_report(y_true, y_pred)
        return metrics

    @property
    def is_fitted(self) -&gt; bool:
        &#34;&#34;&#34;
        Tries to load model from memory/disk, if it fails, returns False, else returns True
        &#34;&#34;&#34;
        try:
            self.model
        except TrainingRequired:
            return False
        return True

    def get_total_train_val_set_per_risk(self) -&gt; Generator:
        dataset = self.dataset
        labeled = dataset[self.train_mask]
        for label in self.lab_names:
            train_mask = ~pd.isnull(dataset[label])
            labeled = dataset.loc[train_mask, :]
            try:
                train_set, valid_set = train_test_split(
                    labeled,
                    test_size=0.3,
                    random_state=RANDOM_SEED,
                    stratify=labeled[label],
                )
            except ValueError:
                print(
                    f&#34;Using normal split for label {label} due to underrepresentated levels.&#34;
                    f&#34; The levels counts for that label are:\n {labeled[label].value_counts()}&#34;
                )
                train_set, valid_set = train_test_split(
                    labeled,
                    test_size=0.3,
                    random_state=RANDOM_SEED,
                )
            yield (label, labeled, [train_set, valid_set])

    @property
    def explainers(self):
        &#34;&#34;&#34;
        The SHAP explainers per model
        &#34;&#34;&#34;
        if self._explainers is None:
            self._explainers = {
                label: shap.Explainer(
                    self.model[label].named_steps[&#34;Classification&#34;].regressor,
                )
                for label in self.model
            }
        return self._explainers

    def train(self) -&gt; None:
        &#34;&#34;&#34;
        - Trains 7 different models, one per each different water security risk.
        - Applies feature selection and generation per different model.
        - Keeps 0.3 validation size, computes classification metrics, saves them, then fits each model to the whole available dataset for each risk.
        - Creates the filled dataset and saves it to disk
        - Creates the prediction mask (what labels from the filled dataset were predicted) and saves it to memory
        &#34;&#34;&#34;
        model = {}
        train_metrics = {}
        valid_metrics = {}
        filled_dataset: pd.DataFrame = None
        importances = {}
        for (
            label,
            labeled,
            [train_set, valid_set],
        ) in self.get_total_train_val_set_per_risk():

            model[label] = Pipeline(
                [
                    (&#34;FeatureSelection&#34;, FeatureSelectionAndGeneration(feats_num=500)),
                    (&#34;Classification&#34;, Classifier(label)),
                ]
            )
            model[label].fit(train_set[self.feat_names], train_set[label])
            train_preds = model[label].predict(train_set[self.feat_names])
            valid_preds = model[label].predict(valid_set[self.feat_names])
            train_metrics[label] = self.compute_metrics(train_set[label], train_preds)
            valid_metrics[label] = self.compute_metrics(valid_set[label], valid_preds)
            model[label].fit(labeled[self.feat_names], labeled[label])
            importances[label] = (
                model[label].named_steps[&#34;Classification&#34;].feature_importances_
            )
            if filled_dataset is None:
                filled_dataset = self.dataset[self.id_columns + self.lab_names].copy()
            filled_dataset.loc[~self.train_mask, label] = model[label].predict(
                self.dataset.loc[~self.train_mask, self.feat_names]
            )
        self.model = model
        self.save_model()
        with open(VALIDATION_METRICS_PATH, &#34;wb&#34;) as out:
            pickle.dump(valid_metrics, out)
        with open(TRAINING_METRICS_PATH, &#34;wb&#34;) as out:
            pickle.dump(train_metrics, out)
        with open(FEATURES_IMPORTANCES_PATH, &#34;wb&#34;) as out:
            pickle.dump(importances, out)
        self.filled_dataset = filled_dataset
        self.filled_dataset.to_csv(FILLED_DATASET_PATH, index=False)
        prediction_mask = self.filled_dataset[self.id_columns + self.lab_names]
        prediction_mask[self.lab_names] = pd.isnull(self.dataset[self.lab_names])
        prediction_mask.to_csv(PREDICTION_MASK_PATH, index=False)
        import data.model.metrics

        importlib.reload(data.model.metrics)
        import data.model.predictions

        importlib.reload(data.model.predictions)

    def test(self, latitude: float, longitude: float):
        &#34;&#34;&#34;
        Given a specific latitude and longitude value, either returns saved predictions from the filled dataset, if the point is close to the
        ones that have already been predicted, or uses a REST API to load the country to which the latitude and longitude refer, uses the country data
        to create the feature vector and computes the prediction using the trained models.
        Returns the series of the found labels, which also contain city and country,
        and the series of booleans which shows which predictions were predicted and which where not.
        IF it is an online prediction, it also returns the shap values associated with the prediction.
        &#34;&#34;&#34;
        try:
            from data.model.predictions import FILLED_DATASET, PREDICTION_MASK
        except ImportError:
            raise TrainingRequired(&#34;Filled Dataset&#34;)
        check_existing = FILLED_DATASET.apply(
            lambda x: is_close((latitude, longitude), (x[&#34;latitude&#34;], x[&#34;longitude&#34;])),
            axis=1,
        )
        if np.any(check_existing):
            labs = list(sorted(self.model.keys()))
            return (
                FILLED_DATASET.loc[check_existing, labs + [&#34;city&#34;, &#34;country&#34;]].iloc[0],
                PREDICTION_MASK.loc[check_existing, labs].iloc[0],
            )
        return self._test_online_prediction(latitude, longitude)

    def _test_online_prediction(self, latitude, longitude):
        try:
            place = get_place(latitude, longitude)
        except AttributeError:
            raise InvalidCoordinates
        population_density = get_average_1k_population_density(latitude, longitude)
        elevation = get_elevation(latitude, longitude)

        from data.unlabeled import COUNTRIES_DATASET

        feats = COUNTRIES_DATASET.loc[place[&#34;code&#34;]].copy()
        feats[&#34;latitude&#34;] = latitude
        feats[&#34;longitude&#34;] = longitude
        feats[&#34;population_1k_density&#34;] = population_density
        feats[&#34;elevation&#34;] = elevation
        feats[&#34;population&#34;] = None
        preds = {}
        mask = {}
        shap_values = {}
        for label in self.model:
            preds[label] = self.model[label].predict(feats)[0]
            mask[label] = True
            transformed = (
                self.model[label].named_steps[&#34;FeatureSelection&#34;].transform(feats)
            )
            shap_values[label] = self.explainers[label](transformed)

        preds[&#34;city&#34;] = place[&#34;city&#34;]
        preds[&#34;country&#34;] = place[&#34;country&#34;]
        return pd.Series(preds), pd.Series(mask), shap_values</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="water_security.classification.model_handler.regression_report"><code class="name flex">
<span>def <span class="ident">regression_report</span></span>(<span>y_true, y_pred)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a regression report, including Mean Absolute and Squared Errors and Explained Variance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def regression_report(y_true, y_pred):
    &#34;&#34;&#34;
    Returns a regression report, including Mean Absolute and Squared Errors and Explained Variance
    &#34;&#34;&#34;
    return {
        &#34;MAE&#34;: mean_absolute_error(y_true, y_pred),
        &#34;MSE&#34;: mean_squared_error(y_true, y_pred),
        &#34;Explained Variance&#34;: explained_variance_score(y_true, y_pred),
    }</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="water_security.classification.model_handler.InvalidCoordinates"><code class="flex name class">
<span>class <span class="ident">InvalidCoordinates</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Common base class for all exceptions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InvalidCoordinates(BaseException):
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler"><code class="flex name class">
<span>class <span class="ident">ModelHandler</span></span>
</code></dt>
<dd>
<div class="desc"><p>Trains and Tests the model, while also computing metrics.
During training the model is first fitted, then produces predictions for any unlabled points inside the dataset
During testing, it receives latitude, longitude, computes the required features for the city, merges with the country features,
uses the model to predict the output and also output the shap values associated with it.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ModelHandler:
    &#34;&#34;&#34;
    Trains and Tests the model, while also computing metrics.
    During training the model is first fitted, then produces predictions for any unlabled points inside the dataset
    During testing, it receives latitude, longitude, computes the required features for the city, merges with the country features,
    uses the model to predict the output and also output the shap values associated with it.
    &#34;&#34;&#34;

    def __init__(self):
        self._model = None
        self._explainers = None
        self._dataset = None
        self._valid_metrics = None
        self._train_metrics = None
        self._filled_dataset = None
        self.train_mask = None
        self.feat_names = None
        self.lab_names = None
        # The id columns to remain in the filled dataset
        self.id_columns = [
            &#34;city&#34;,
            &#34;country&#34;,
            &#34;country_code&#34;,
            &#34;c40&#34;,
            &#34;latitude&#34;,
            &#34;longitude&#34;,
            &#34;population_1k_density&#34;,
            &#34;elevation&#34;,
        ]
        # The id columns to consider also as features
        self.feat_id_columns = [
            &#34;latitude&#34;,
            &#34;longitude&#34;,
            &#34;population_1k_density&#34;,
            &#34;elevation&#34;,
        ]

    @property
    def model(self) -&gt; Pipeline:
        &#34;&#34;&#34;
        If model is not defined, try to loaded from disk
        &#34;&#34;&#34;
        if self._model is None:
            try:
                from data.model import MODEL, MODEL_PATH

                print(f&#34;Loaded model from {MODEL_PATH}.&#34;)
                self._model = MODEL
            except ImportError:
                raise TrainingRequired(&#34;Model&#34;)
        return self._model

    @model.setter
    def model(self, model: Pipeline):
        self._model = model

    def save_model(self) -&gt; None:
        &#34;&#34;&#34;
        Saves model to memory
        &#34;&#34;&#34;
        with open(os.path.join(MODEL_PATH), &#34;wb&#34;) as out:
            pickle.dump(self.model, out)
        import data.model

        importlib.reload(data.model)

    @property
    def dataset(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        The dataset for the training step.
        When it is loaded the first time, several variables are defined:
            - lab_names: the labels names/columns of the dataset
            - unique_labs: the unique labels values
            - feat_names: the features names/columns of the dataset
            - train_mask: the mask that refers to the cities that are labeled at least for one risk
        &#34;&#34;&#34;
        if self._dataset is None:
            from data.dataset import DATASET as dataset
            from data.labeled.preprocessed import LABELED_CITIES, RISKS_MAPPING

            self.lab_names = sorted(RISKS_MAPPING.keys())
            self.unique_labs = np.unique(dataset[self.lab_names].T.stack().values)
            self.feat_names = [
                x
                for x in dataset.columns
                if x not in self.lab_names
                and (x in self.feat_id_columns or x not in self.id_columns)
            ]
            self.train_mask = dataset[self.lab_names].apply(
                lambda x: not all(pd.isnull(x)), axis=1
            )
            self._dataset = dataset
        return self._dataset

    @property
    def filled_dataset(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        The dataset that has filled labels, which were produced from the predictions
        &#34;&#34;&#34;
        if self._filled_dataset is None:
            try:
                self._filled_dataset = pd.read_csv(FILLED_DATASET_PATH)
            except IOError:
                raise TrainingRequired(&#34;Filled Dataset&#34;)
        return self._filled_dataset

    @filled_dataset.setter
    def filled_dataset(self, dataset: pd.DataFrame):
        self._filled_dataset = dataset

    def compute_metrics(self, y_true, y_pred):
        &#34;&#34;&#34;
        Compute metrics for regression labels of size nx1
        &#34;&#34;&#34;
        metrics = {}

        # Interpolate predictions to labels, eg convert 0.2 to 0, 0.7 to 1 etc.
        y_pred_interp = self.unique_labs[
            np.abs(np.reshape(self.unique_labs, (-1, 1)) - y_pred).argmin(axis=0)
        ]
        metrics[&#34;confusion_matrix&#34;] = confusion_matrix(y_true, y_pred_interp)
        metrics[&#34;classification_report&#34;] = classification_report(
            y_true, y_pred_interp, output_dict=True
        )
        metrics[&#34;regression_report&#34;] = regression_report(y_true, y_pred)
        return metrics

    @property
    def is_fitted(self) -&gt; bool:
        &#34;&#34;&#34;
        Tries to load model from memory/disk, if it fails, returns False, else returns True
        &#34;&#34;&#34;
        try:
            self.model
        except TrainingRequired:
            return False
        return True

    def get_total_train_val_set_per_risk(self) -&gt; Generator:
        dataset = self.dataset
        labeled = dataset[self.train_mask]
        for label in self.lab_names:
            train_mask = ~pd.isnull(dataset[label])
            labeled = dataset.loc[train_mask, :]
            try:
                train_set, valid_set = train_test_split(
                    labeled,
                    test_size=0.3,
                    random_state=RANDOM_SEED,
                    stratify=labeled[label],
                )
            except ValueError:
                print(
                    f&#34;Using normal split for label {label} due to underrepresentated levels.&#34;
                    f&#34; The levels counts for that label are:\n {labeled[label].value_counts()}&#34;
                )
                train_set, valid_set = train_test_split(
                    labeled,
                    test_size=0.3,
                    random_state=RANDOM_SEED,
                )
            yield (label, labeled, [train_set, valid_set])

    @property
    def explainers(self):
        &#34;&#34;&#34;
        The SHAP explainers per model
        &#34;&#34;&#34;
        if self._explainers is None:
            self._explainers = {
                label: shap.Explainer(
                    self.model[label].named_steps[&#34;Classification&#34;].regressor,
                )
                for label in self.model
            }
        return self._explainers

    def train(self) -&gt; None:
        &#34;&#34;&#34;
        - Trains 7 different models, one per each different water security risk.
        - Applies feature selection and generation per different model.
        - Keeps 0.3 validation size, computes classification metrics, saves them, then fits each model to the whole available dataset for each risk.
        - Creates the filled dataset and saves it to disk
        - Creates the prediction mask (what labels from the filled dataset were predicted) and saves it to memory
        &#34;&#34;&#34;
        model = {}
        train_metrics = {}
        valid_metrics = {}
        filled_dataset: pd.DataFrame = None
        importances = {}
        for (
            label,
            labeled,
            [train_set, valid_set],
        ) in self.get_total_train_val_set_per_risk():

            model[label] = Pipeline(
                [
                    (&#34;FeatureSelection&#34;, FeatureSelectionAndGeneration(feats_num=500)),
                    (&#34;Classification&#34;, Classifier(label)),
                ]
            )
            model[label].fit(train_set[self.feat_names], train_set[label])
            train_preds = model[label].predict(train_set[self.feat_names])
            valid_preds = model[label].predict(valid_set[self.feat_names])
            train_metrics[label] = self.compute_metrics(train_set[label], train_preds)
            valid_metrics[label] = self.compute_metrics(valid_set[label], valid_preds)
            model[label].fit(labeled[self.feat_names], labeled[label])
            importances[label] = (
                model[label].named_steps[&#34;Classification&#34;].feature_importances_
            )
            if filled_dataset is None:
                filled_dataset = self.dataset[self.id_columns + self.lab_names].copy()
            filled_dataset.loc[~self.train_mask, label] = model[label].predict(
                self.dataset.loc[~self.train_mask, self.feat_names]
            )
        self.model = model
        self.save_model()
        with open(VALIDATION_METRICS_PATH, &#34;wb&#34;) as out:
            pickle.dump(valid_metrics, out)
        with open(TRAINING_METRICS_PATH, &#34;wb&#34;) as out:
            pickle.dump(train_metrics, out)
        with open(FEATURES_IMPORTANCES_PATH, &#34;wb&#34;) as out:
            pickle.dump(importances, out)
        self.filled_dataset = filled_dataset
        self.filled_dataset.to_csv(FILLED_DATASET_PATH, index=False)
        prediction_mask = self.filled_dataset[self.id_columns + self.lab_names]
        prediction_mask[self.lab_names] = pd.isnull(self.dataset[self.lab_names])
        prediction_mask.to_csv(PREDICTION_MASK_PATH, index=False)
        import data.model.metrics

        importlib.reload(data.model.metrics)
        import data.model.predictions

        importlib.reload(data.model.predictions)

    def test(self, latitude: float, longitude: float):
        &#34;&#34;&#34;
        Given a specific latitude and longitude value, either returns saved predictions from the filled dataset, if the point is close to the
        ones that have already been predicted, or uses a REST API to load the country to which the latitude and longitude refer, uses the country data
        to create the feature vector and computes the prediction using the trained models.
        Returns the series of the found labels, which also contain city and country,
        and the series of booleans which shows which predictions were predicted and which where not.
        IF it is an online prediction, it also returns the shap values associated with the prediction.
        &#34;&#34;&#34;
        try:
            from data.model.predictions import FILLED_DATASET, PREDICTION_MASK
        except ImportError:
            raise TrainingRequired(&#34;Filled Dataset&#34;)
        check_existing = FILLED_DATASET.apply(
            lambda x: is_close((latitude, longitude), (x[&#34;latitude&#34;], x[&#34;longitude&#34;])),
            axis=1,
        )
        if np.any(check_existing):
            labs = list(sorted(self.model.keys()))
            return (
                FILLED_DATASET.loc[check_existing, labs + [&#34;city&#34;, &#34;country&#34;]].iloc[0],
                PREDICTION_MASK.loc[check_existing, labs].iloc[0],
            )
        return self._test_online_prediction(latitude, longitude)

    def _test_online_prediction(self, latitude, longitude):
        try:
            place = get_place(latitude, longitude)
        except AttributeError:
            raise InvalidCoordinates
        population_density = get_average_1k_population_density(latitude, longitude)
        elevation = get_elevation(latitude, longitude)

        from data.unlabeled import COUNTRIES_DATASET

        feats = COUNTRIES_DATASET.loc[place[&#34;code&#34;]].copy()
        feats[&#34;latitude&#34;] = latitude
        feats[&#34;longitude&#34;] = longitude
        feats[&#34;population_1k_density&#34;] = population_density
        feats[&#34;elevation&#34;] = elevation
        feats[&#34;population&#34;] = None
        preds = {}
        mask = {}
        shap_values = {}
        for label in self.model:
            preds[label] = self.model[label].predict(feats)[0]
            mask[label] = True
            transformed = (
                self.model[label].named_steps[&#34;FeatureSelection&#34;].transform(feats)
            )
            shap_values[label] = self.explainers[label](transformed)

        preds[&#34;city&#34;] = place[&#34;city&#34;]
        preds[&#34;country&#34;] = place[&#34;country&#34;]
        return pd.Series(preds), pd.Series(mask), shap_values</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="water_security.classification.model_handler.ModelHandler.dataset"><code class="name">var <span class="ident">dataset</span> : pandas.core.frame.DataFrame</code></dt>
<dd>
<div class="desc"><p>The dataset for the training step.
When it is loaded the first time, several variables are defined:
- lab_names: the labels names/columns of the dataset
- unique_labs: the unique labels values
- feat_names: the features names/columns of the dataset
- train_mask: the mask that refers to the cities that are labeled at least for one risk</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def dataset(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    The dataset for the training step.
    When it is loaded the first time, several variables are defined:
        - lab_names: the labels names/columns of the dataset
        - unique_labs: the unique labels values
        - feat_names: the features names/columns of the dataset
        - train_mask: the mask that refers to the cities that are labeled at least for one risk
    &#34;&#34;&#34;
    if self._dataset is None:
        from data.dataset import DATASET as dataset
        from data.labeled.preprocessed import LABELED_CITIES, RISKS_MAPPING

        self.lab_names = sorted(RISKS_MAPPING.keys())
        self.unique_labs = np.unique(dataset[self.lab_names].T.stack().values)
        self.feat_names = [
            x
            for x in dataset.columns
            if x not in self.lab_names
            and (x in self.feat_id_columns or x not in self.id_columns)
        ]
        self.train_mask = dataset[self.lab_names].apply(
            lambda x: not all(pd.isnull(x)), axis=1
        )
        self._dataset = dataset
    return self._dataset</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.explainers"><code class="name">var <span class="ident">explainers</span></code></dt>
<dd>
<div class="desc"><p>The SHAP explainers per model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def explainers(self):
    &#34;&#34;&#34;
    The SHAP explainers per model
    &#34;&#34;&#34;
    if self._explainers is None:
        self._explainers = {
            label: shap.Explainer(
                self.model[label].named_steps[&#34;Classification&#34;].regressor,
            )
            for label in self.model
        }
    return self._explainers</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.filled_dataset"><code class="name">var <span class="ident">filled_dataset</span> : pandas.core.frame.DataFrame</code></dt>
<dd>
<div class="desc"><p>The dataset that has filled labels, which were produced from the predictions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def filled_dataset(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    The dataset that has filled labels, which were produced from the predictions
    &#34;&#34;&#34;
    if self._filled_dataset is None:
        try:
            self._filled_dataset = pd.read_csv(FILLED_DATASET_PATH)
        except IOError:
            raise TrainingRequired(&#34;Filled Dataset&#34;)
    return self._filled_dataset</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.is_fitted"><code class="name">var <span class="ident">is_fitted</span> : bool</code></dt>
<dd>
<div class="desc"><p>Tries to load model from memory/disk, if it fails, returns False, else returns True</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def is_fitted(self) -&gt; bool:
    &#34;&#34;&#34;
    Tries to load model from memory/disk, if it fails, returns False, else returns True
    &#34;&#34;&#34;
    try:
        self.model
    except TrainingRequired:
        return False
    return True</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.model"><code class="name">var <span class="ident">model</span> : sklearn.pipeline.Pipeline</code></dt>
<dd>
<div class="desc"><p>If model is not defined, try to loaded from disk</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def model(self) -&gt; Pipeline:
    &#34;&#34;&#34;
    If model is not defined, try to loaded from disk
    &#34;&#34;&#34;
    if self._model is None:
        try:
            from data.model import MODEL, MODEL_PATH

            print(f&#34;Loaded model from {MODEL_PATH}.&#34;)
            self._model = MODEL
        except ImportError:
            raise TrainingRequired(&#34;Model&#34;)
    return self._model</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="water_security.classification.model_handler.ModelHandler.compute_metrics"><code class="name flex">
<span>def <span class="ident">compute_metrics</span></span>(<span>self, y_true, y_pred)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute metrics for regression labels of size nx1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_metrics(self, y_true, y_pred):
    &#34;&#34;&#34;
    Compute metrics for regression labels of size nx1
    &#34;&#34;&#34;
    metrics = {}

    # Interpolate predictions to labels, eg convert 0.2 to 0, 0.7 to 1 etc.
    y_pred_interp = self.unique_labs[
        np.abs(np.reshape(self.unique_labs, (-1, 1)) - y_pred).argmin(axis=0)
    ]
    metrics[&#34;confusion_matrix&#34;] = confusion_matrix(y_true, y_pred_interp)
    metrics[&#34;classification_report&#34;] = classification_report(
        y_true, y_pred_interp, output_dict=True
    )
    metrics[&#34;regression_report&#34;] = regression_report(y_true, y_pred)
    return metrics</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.get_total_train_val_set_per_risk"><code class="name flex">
<span>def <span class="ident">get_total_train_val_set_per_risk</span></span>(<span>self) ‑> Generator</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_total_train_val_set_per_risk(self) -&gt; Generator:
    dataset = self.dataset
    labeled = dataset[self.train_mask]
    for label in self.lab_names:
        train_mask = ~pd.isnull(dataset[label])
        labeled = dataset.loc[train_mask, :]
        try:
            train_set, valid_set = train_test_split(
                labeled,
                test_size=0.3,
                random_state=RANDOM_SEED,
                stratify=labeled[label],
            )
        except ValueError:
            print(
                f&#34;Using normal split for label {label} due to underrepresentated levels.&#34;
                f&#34; The levels counts for that label are:\n {labeled[label].value_counts()}&#34;
            )
            train_set, valid_set = train_test_split(
                labeled,
                test_size=0.3,
                random_state=RANDOM_SEED,
            )
        yield (label, labeled, [train_set, valid_set])</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.save_model"><code class="name flex">
<span>def <span class="ident">save_model</span></span>(<span>self) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>Saves model to memory</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_model(self) -&gt; None:
    &#34;&#34;&#34;
    Saves model to memory
    &#34;&#34;&#34;
    with open(os.path.join(MODEL_PATH), &#34;wb&#34;) as out:
        pickle.dump(self.model, out)
    import data.model

    importlib.reload(data.model)</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.test"><code class="name flex">
<span>def <span class="ident">test</span></span>(<span>self, latitude: float, longitude: float)</span>
</code></dt>
<dd>
<div class="desc"><p>Given a specific latitude and longitude value, either returns saved predictions from the filled dataset, if the point is close to the
ones that have already been predicted, or uses a REST API to load the country to which the latitude and longitude refer, uses the country data
to create the feature vector and computes the prediction using the trained models.
Returns the series of the found labels, which also contain city and country,
and the series of booleans which shows which predictions were predicted and which where not.
IF it is an online prediction, it also returns the shap values associated with the prediction.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test(self, latitude: float, longitude: float):
    &#34;&#34;&#34;
    Given a specific latitude and longitude value, either returns saved predictions from the filled dataset, if the point is close to the
    ones that have already been predicted, or uses a REST API to load the country to which the latitude and longitude refer, uses the country data
    to create the feature vector and computes the prediction using the trained models.
    Returns the series of the found labels, which also contain city and country,
    and the series of booleans which shows which predictions were predicted and which where not.
    IF it is an online prediction, it also returns the shap values associated with the prediction.
    &#34;&#34;&#34;
    try:
        from data.model.predictions import FILLED_DATASET, PREDICTION_MASK
    except ImportError:
        raise TrainingRequired(&#34;Filled Dataset&#34;)
    check_existing = FILLED_DATASET.apply(
        lambda x: is_close((latitude, longitude), (x[&#34;latitude&#34;], x[&#34;longitude&#34;])),
        axis=1,
    )
    if np.any(check_existing):
        labs = list(sorted(self.model.keys()))
        return (
            FILLED_DATASET.loc[check_existing, labs + [&#34;city&#34;, &#34;country&#34;]].iloc[0],
            PREDICTION_MASK.loc[check_existing, labs].iloc[0],
        )
    return self._test_online_prediction(latitude, longitude)</code></pre>
</details>
</dd>
<dt id="water_security.classification.model_handler.ModelHandler.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>Trains 7 different models, one per each different water security risk.</li>
<li>Applies feature selection and generation per different model.</li>
<li>Keeps 0.3 validation size, computes classification metrics, saves them, then fits each model to the whole available dataset for each risk.</li>
<li>Creates the filled dataset and saves it to disk</li>
<li>Creates the prediction mask (what labels from the filled dataset were predicted) and saves it to memory</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self) -&gt; None:
    &#34;&#34;&#34;
    - Trains 7 different models, one per each different water security risk.
    - Applies feature selection and generation per different model.
    - Keeps 0.3 validation size, computes classification metrics, saves them, then fits each model to the whole available dataset for each risk.
    - Creates the filled dataset and saves it to disk
    - Creates the prediction mask (what labels from the filled dataset were predicted) and saves it to memory
    &#34;&#34;&#34;
    model = {}
    train_metrics = {}
    valid_metrics = {}
    filled_dataset: pd.DataFrame = None
    importances = {}
    for (
        label,
        labeled,
        [train_set, valid_set],
    ) in self.get_total_train_val_set_per_risk():

        model[label] = Pipeline(
            [
                (&#34;FeatureSelection&#34;, FeatureSelectionAndGeneration(feats_num=500)),
                (&#34;Classification&#34;, Classifier(label)),
            ]
        )
        model[label].fit(train_set[self.feat_names], train_set[label])
        train_preds = model[label].predict(train_set[self.feat_names])
        valid_preds = model[label].predict(valid_set[self.feat_names])
        train_metrics[label] = self.compute_metrics(train_set[label], train_preds)
        valid_metrics[label] = self.compute_metrics(valid_set[label], valid_preds)
        model[label].fit(labeled[self.feat_names], labeled[label])
        importances[label] = (
            model[label].named_steps[&#34;Classification&#34;].feature_importances_
        )
        if filled_dataset is None:
            filled_dataset = self.dataset[self.id_columns + self.lab_names].copy()
        filled_dataset.loc[~self.train_mask, label] = model[label].predict(
            self.dataset.loc[~self.train_mask, self.feat_names]
        )
    self.model = model
    self.save_model()
    with open(VALIDATION_METRICS_PATH, &#34;wb&#34;) as out:
        pickle.dump(valid_metrics, out)
    with open(TRAINING_METRICS_PATH, &#34;wb&#34;) as out:
        pickle.dump(train_metrics, out)
    with open(FEATURES_IMPORTANCES_PATH, &#34;wb&#34;) as out:
        pickle.dump(importances, out)
    self.filled_dataset = filled_dataset
    self.filled_dataset.to_csv(FILLED_DATASET_PATH, index=False)
    prediction_mask = self.filled_dataset[self.id_columns + self.lab_names]
    prediction_mask[self.lab_names] = pd.isnull(self.dataset[self.lab_names])
    prediction_mask.to_csv(PREDICTION_MASK_PATH, index=False)
    import data.model.metrics

    importlib.reload(data.model.metrics)
    import data.model.predictions

    importlib.reload(data.model.predictions)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="water_security.classification.model_handler.TrainingRequired"><code class="flex name class">
<span>class <span class="ident">TrainingRequired</span></span>
<span>(</span><span>obj)</span>
</code></dt>
<dd>
<div class="desc"><p>Exception class to raise if estimator is used before fitting.</p>
<p>This class inherits from both ValueError and AttributeError to help with
exception handling and backward compatibility.</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; from sklearn.svm import LinearSVC
&gt;&gt;&gt; from sklearn.exceptions import NotFittedError
&gt;&gt;&gt; try:
...     LinearSVC().predict([[1, 2], [2, 3], [3, 4]])
... except NotFittedError as e:
...     print(repr(e))
NotFittedError(&quot;This LinearSVC instance is not fitted yet. Call 'fit' with
appropriate arguments before using this estimator.&quot;...)
</code></pre>
<div class="admonition versionchanged">
<p class="admonition-title">Changed in version:&ensp;0.18</p>
<p>Moved from sklearn.utils.validation.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TrainingRequired(NotFittedError):
    def __init__(self, obj):
        super().__init__(f&#34;{obj} could not be loaded. Training model is required&#34;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>sklearn.exceptions.NotFittedError</li>
<li>builtins.ValueError</li>
<li>builtins.AttributeError</li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="water_security.classification" href="index.html">water_security.classification</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="water_security.classification.model_handler.regression_report" href="#water_security.classification.model_handler.regression_report">regression_report</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="water_security.classification.model_handler.InvalidCoordinates" href="#water_security.classification.model_handler.InvalidCoordinates">InvalidCoordinates</a></code></h4>
</li>
<li>
<h4><code><a title="water_security.classification.model_handler.ModelHandler" href="#water_security.classification.model_handler.ModelHandler">ModelHandler</a></code></h4>
<ul class="">
<li><code><a title="water_security.classification.model_handler.ModelHandler.compute_metrics" href="#water_security.classification.model_handler.ModelHandler.compute_metrics">compute_metrics</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.dataset" href="#water_security.classification.model_handler.ModelHandler.dataset">dataset</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.explainers" href="#water_security.classification.model_handler.ModelHandler.explainers">explainers</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.filled_dataset" href="#water_security.classification.model_handler.ModelHandler.filled_dataset">filled_dataset</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.get_total_train_val_set_per_risk" href="#water_security.classification.model_handler.ModelHandler.get_total_train_val_set_per_risk">get_total_train_val_set_per_risk</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.is_fitted" href="#water_security.classification.model_handler.ModelHandler.is_fitted">is_fitted</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.model" href="#water_security.classification.model_handler.ModelHandler.model">model</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.save_model" href="#water_security.classification.model_handler.ModelHandler.save_model">save_model</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.test" href="#water_security.classification.model_handler.ModelHandler.test">test</a></code></li>
<li><code><a title="water_security.classification.model_handler.ModelHandler.train" href="#water_security.classification.model_handler.ModelHandler.train">train</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="water_security.classification.model_handler.TrainingRequired" href="#water_security.classification.model_handler.TrainingRequired">TrainingRequired</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>